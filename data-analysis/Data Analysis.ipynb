{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "This notebook goes through the training data.  First by visualizing the data in two dimensions.  Second, by analyzing the data feature by feature to see what patterns arise.  But before you have training data, you need to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the dataset you want to analyze? >credit card default\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datasetName = input(\"What is the name of the dataset you want to analyze? >\")\n",
    "datasetFileName = \"raw-data/\" + datasetName + \".xls\"\n",
    "\n",
    "rawFrame = pd.read_excel(datasetFileName)\n",
    "\n",
    "# grab a sample of 40% of the data, this will be split in half for the validation and test sets\n",
    "validTestFrame = rawFrame.sample(frac=0.4)\n",
    "validFrame = validTestFrame.sample(frac=.5)\n",
    "testFrame = validTestFrame.drop(validFrame.index)\n",
    "\n",
    "# the training set becomes what's left\n",
    "trainFrame = rawFrame.drop(validTestFrame.index)\n",
    "\n",
    "# and to put the split data into excel files for later\n",
    "trainFileName = \"raw-data/\" + datasetName + \"-train.xls\"\n",
    "validFileName = \"raw-data/\" + datasetName + \"-valid.xls\"\n",
    "testFileName = \"raw-data/\" + datasetName + \"-test.xls\"\n",
    "trainFrame.to_excel(trainFileName, index=False)\n",
    "validFrame.to_excel(validFileName, index=False)\n",
    "testFrame.to_excel(testFileName, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the datasets split, now we can continue to use the training set to analyze the data.  One thing that can be done to understand the data is to compress the data into two dimensions, using either Principal Component Analysis (PCA) or Linear Discriminant Analysis (LDA).  According to what I've read, PCA is useful when you don't know what the labels could be, and LDA is useful when you do know the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
